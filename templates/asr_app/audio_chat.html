{% extends 'base.html' %}
{% load static %}

{% block title %}Audio Chat - Nepali + English ASR{% endblock %}

{% block container_class %}-sm{% endblock %}

{% block extra_css %}
<style>
    .audio-chat-container {
        display: flex;
        flex-direction: column;
        gap: 20px;
    }
    
    .page-header {
        margin-bottom: 20px;
    }
    
    .page-header h2 {
        font-size: 28px;
        margin: 0 0 8px 0;
        color: #1a1a1a;
        font-weight: 700;
    }
    
    .page-header p {
        font-size: 15px;
        color: #666;
        margin: 0;
    }
    
    .chat-settings {
        display: flex;
        gap: 20px;
        align-items: center;
        flex-wrap: wrap;
        margin: 20px 0;
        padding: 20px;
        background: white;
        border-radius: 8px;
        box-shadow: 0 1px 3px rgba(0, 0, 0, 0.05);
    }
    
    .setting-group {
        display: flex;
        align-items: center;
        gap: 8px;
    }
    
    .setting-group label {
        margin: 0;
        font-size: 14px;
        color: #333;
        font-weight: 600;
    }
    
    .setting-group select {
        padding: 8px 12px;
        border: 1px solid #ddd;
        border-radius: 6px;
        font-size: 14px;
        background: white;
        cursor: pointer;
        color: #333;
        font-weight: 500;
    }
    
    .setting-group select:focus {
        outline: none;
        border-color: #667eea;
        box-shadow: 0 0 0 3px rgba(102, 126, 234, 0.1);
    }
    
    .chat-messages {
        flex: 1;
        min-height: 300px;
        max-height: 500px;
        overflow-y: auto;
        padding: 20px;
        background: white;
        border-radius: 8px;
        display: flex;
        flex-direction: column;
        gap: 12px;
        box-shadow: 0 1px 3px rgba(0, 0, 0, 0.05);
    }
    
    .message {
        display: flex;
        gap: 10px;
        animation: slideIn 0.3s ease-out;
    }
    
    @keyframes slideIn {
        from {
            opacity: 0;
            transform: translateY(10px);
        }
        to {
            opacity: 1;
            transform: translateY(0);
        }
    }
    
    .message.user {
        justify-content: flex-end;
    }
    
    .message.assistant {
        justify-content: flex-start;
    }
    
    .message-content {
        max-width: 70%;
        padding: 12px 14px;
        border-radius: 10px;
        background: #f0f2f5;
        box-shadow: 0 1px 2px rgba(0, 0, 0, 0.05);
    }
    
    .message.user .message-content {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
    }
    
    .message-text {
        margin: 0 0 6px 0;
        font-size: 14px;
        line-height: 1.4;
        color: #222;
    }
    
    .message.user .message-text {
        color: white;
    }
    
    .message-audio audio {
        max-width: 100%;
        border-radius: 4px;
        height: 28px;
        margin: 6px 0;
    }
    
    .message-audio-original,
    .message-audio-translated {
        font-size: 11px;
        color: #666;
        margin: 6px 0;
    }
    
    .message.user .message-audio-original,
    .message.user .message-audio-translated {
        color: rgba(255, 255, 255, 0.85);
    }
    
    .message-status {
        font-size: 11px;
        margin-top: 4px;
    }
    
    .status-badge {
        display: inline-block;
        padding: 3px 8px;
        border-radius: 10px;
        font-size: 10px;
        font-weight: 600;
        text-transform: uppercase;
        letter-spacing: 0.2px;
    }
    
    .status-pending {
        background: #fff3cd;
        color: #856404;
    }
    
    .status-transcribing {
        background: #cfe2ff;
        color: #084298;
    }
    
    .status-translating {
        background: #e2d5f5;
        color: #5d2e8c;
    }
    
    .status-completed {
        background: #d1f0e5;
        color: #0f5132;
    }
    
    .status-failed {
        background: #f8d7da;
        color: #842029;
    }
    
    .card {
        background: white;
        border-radius: 8px;
        padding: 20px;
        box-shadow: 0 1px 3px rgba(0, 0, 0, 0.05);
    }
    
    .input-controls {
        display: flex;
        gap: 12px;
        align-items: center;
        flex-wrap: wrap;
    }
    
    .record-button {
        width: 60px;
        height: 60px;
        border-radius: 50%;
        border: none;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        font-size: 28px;
        cursor: pointer;
        display: flex;
        flex-direction: column;
        align-items: center;
        justify-content: center;
        transition: all 0.3s ease;
        box-shadow: 0 2px 8px rgba(102, 126, 234, 0.3);
        flex-shrink: 0;
    }
    
    .record-button:hover {
        transform: scale(1.1);
        box-shadow: 0 4px 12px rgba(102, 126, 234, 0.4);
    }
    
    .record-button:active {
        transform: scale(0.95);
    }
    
    .recording-timer {
        font-size: 13px;
        font-weight: 700;
        color: #667eea;
        min-width: 75px;
        text-align: center;
        flex-shrink: 0;
        font-family: 'Monaco', 'Courier', monospace;
    }
    
    .recording-timer#silence-timer {
        color: #ff6b6b;
    }
    
    .input-text {
        flex: 1;
        min-width: 150px;
        padding: 12px 14px;
        border: 1px solid #ddd;
        border-radius: 6px;
        font-size: 14px;
        font-family: inherit;
        transition: all 0.3s ease;
        color: #333;
    }
    
    .input-text::placeholder {
        color: #999;
    }
    
    .input-text:focus {
        outline: none;
        border-color: #667eea;
        box-shadow: 0 0 0 3px rgba(102, 126, 234, 0.1);
    }
    
    .send-button {
        padding: 10px 20px;
        border: none;
        border-radius: 6px;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        cursor: pointer;
        font-weight: 600;
        font-size: 14px;
        transition: all 0.3s ease;
        box-shadow: 0 1px 3px rgba(102, 126, 234, 0.2);
        flex-shrink: 0;
    }
    
    .send-button:hover {
        transform: translateY(-1px);
        box-shadow: 0 2px 6px rgba(102, 126, 234, 0.3);
    }
    
    .send-button:active {
        transform: translateY(0);
    }
    
    .send-button:disabled {
        opacity: 0.5;
        cursor: not-allowed;
    }
    
    .audio-waveform {
        display: flex;
        align-items: center;
        justify-content: center;
        gap: 2px;
        height: 20px;
    }
    
    .waveform-bar {
        width: 2px;
        background: #667eea;
        border-radius: 1px;
        animation: wave 0.6s ease-in-out infinite;
    }
    
    .waveform-bar:nth-child(1) { animation-delay: 0s; }
    .waveform-bar:nth-child(2) { animation-delay: 0.1s; }
    .waveform-bar:nth-child(3) { animation-delay: 0.2s; }
    
    @keyframes wave {
        0%, 100% { height: 3px; }
        50% { height: 14px; }
    }
    
    #listening-indicator {
        gap: 8px;
        font-size: 13px;
        color: #667eea;
        font-weight: 600;
    }
    
    @media (max-width: 768px) {
        .message-content {
            max-width: 85%;
        }
        
        .chat-settings {
            gap: 12px;
        }
        
        .record-button {
            width: 52px;
            height: 52px;
            font-size: 24px;
        }
    }
</style>
{% endblock %}

{% block content %}
<div class="audio-chat-container">
    <!-- Page Header -->
    <div class="page-header">
        <h2>üé§ Audio Chat - Live Translation</h2>
        <p>Speak naturally - auto-detects pauses and sends messages</p>
    </div>
    
    <!-- Settings -->
    <div class="chat-settings">
        <div class="setting-group">
            <label for="source-lang">Source:</label>
            <select id="source-lang">
                <option value="ne">‡§®‡•á‡§™‡§æ‡§≤‡•Ä (Nepali)</option>
                <option value="en">English</option>
                <option value="mixed" selected>Mixed</option>
            </select>
        </div>
        <div class="setting-group">
            <label for="target-lang">Target:</label>
            <select id="target-lang">
                <option value="ne">‡§®‡•á‡§™‡§æ‡§≤‡•Ä (Nepali)</option>
                <option value="en" selected>English</option>
            </select>
        </div>
        <div class="setting-group">
            <label>
                <input type="checkbox" id="auto-play" checked>
                Auto-play Translation
            </label>
        </div>
    </div>
    
    <!-- Messages Card -->
    <div class="card">
        <div class="chat-messages" id="messages">
            <div style="text-align: center; color: #999; padding: 40px 20px;">
                <p>üëÇ No messages yet. Click Start to begin!</p>
            </div>
        </div>
    </div>
    
    <!-- Input Card -->
    <div class="card">
        <div class="input-controls">
            <button class="record-button" id="start-btn" title="Start conversation">
                üéôÔ∏è
            </button>
            <span class="recording-timer" id="session-timer" style="display: none;">0:00</span>
            <span class="recording-timer" id="silence-timer" style="display: none;">--</span>
            <div style="flex: 1; display: flex; align-items: center; gap: 8px;">
                <div id="listening-indicator" style="display: none;">
                    <span>Listening...</span>
                    <div class="audio-waveform">
                        <div class="waveform-bar"></div>
                        <div class="waveform-bar"></div>
                        <div class="waveform-bar"></div>
                    </div>
                </div>
            </div>
            <input type="text" class="input-text" id="text-input" placeholder="Or type a message..." style="display: none;" />
            <button class="send-button" id="send-text-btn" style="display: none;">Send</button>
            <button class="send-button" id="stop-btn" style="display: none; background: linear-gradient(135deg, #ff6b6b 0%, #ff5252 100%);">Stop</button>
        </div>
    </div>
</div>

<script>
    // WebSocket setup
    const chatId = '{{ chat_id }}';
    const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
    const socket = new WebSocket(`${protocol}//${window.location.host}/ws/audio-chat/${chatId}/`);
    
    // Audio recording - Siri-like continuous mode
    let mediaRecorder = null;
    let audioContext = null;
    let analyser = null;
    let isSessionActive = false;
    let recordingChunks = [];
    let sessionStartTime = null;
    let sessionTimerInterval = null;
    let silenceDetectionTimeout = null;
    let silenceTimerInterval = null;
    let silenceStartTime = null;
    let lastSpeechTime = null;
    let consecutiveSilenceChecks = 0;
    let continuousSendInterval = null;
    let speechDetectedSinceLastSend = false;
    let currentMessageTempId = null; // Track message for continuous sends
    let currentMessageHasGoodText = false; // Track if message has real transcription
    let speechChecksInWindow = 0; // Count speech checks in current 2s window
    let totalChecksInWindow = 0; // Total checks in current 2s window
    
    // Voice Activity Detection thresholds
    const SPEECH_THRESHOLD = 40;    // If level > 40, it's speech
    const CONTINUOUS_SEND_INTERVAL = 2000; // Send every 2 seconds while speaking
    const SILENCE_CHECKS_NEEDED = 35; // ~35 checks * 150ms = 5.25 seconds
    const CHECK_INTERVAL = 150;     // Check audio level every 150ms
    const MIN_SPEECH_RATIO = 0.4;   // Require 40% of checks to be speech in 2s window
    
    // DOM elements
    const startBtn = document.getElementById('start-btn');
    const stopBtn = document.getElementById('stop-btn');
    const sessionTimer = document.getElementById('session-timer');
    const silenceTimer = document.getElementById('silence-timer');
    const listeningIndicator = document.getElementById('listening-indicator');
    const textInput = document.getElementById('text-input');
    const sendTextBtn = document.getElementById('send-text-btn');
    const messagesDiv = document.getElementById('messages');
    const sourceLangSelect = document.getElementById('source-lang');
    const targetLangSelect = document.getElementById('target-lang');
    const autoPlayCheckbox = document.getElementById('auto-play');
    
    // Initialize WebSocket
    socket.onopen = () => {
        console.log('WebSocket connected');
    };
    
    socket.onmessage = (event) => {
        const data = JSON.parse(event.data);
        handleMessage(data);
    };
    
    socket.onerror = (error) => {
        console.error('WebSocket error:', error);
        showError('Connection error. Please refresh the page.');
    };
    
    socket.onclose = () => {
        console.log('WebSocket disconnected');
    };
    
    // Handle incoming messages
    function handleMessage(data) {
        const type = data.type;
        
        if (type === 'message') {
            const messageData = data.data;
            displayMessage(messageData);
        } else if (type === 'update') {
            updateMessage(data.data);
        } else if (type === 'error') {
            showError(data.message);
        }
    }
    
    // Display message
    function displayMessage(msg) {
        // Remove empty state if exists
        const emptyState = messagesDiv.querySelector('[style*="No messages"]');
        if (emptyState) emptyState.remove();
        
        const messageEl = document.createElement('div');
        messageEl.className = `message ${msg.role}`;
        messageEl.id = `msg-${msg.id || msg.message_id}`;
        
        const contentEl = document.createElement('div');
        contentEl.className = 'message-content';
        
        // Original audio player
        if (msg.audio_file_url) {
            const audioDiv = document.createElement('div');
            audioDiv.className = 'message-audio-original';
            const audioEl = document.createElement('audio');
            audioEl.controls = true;
            audioEl.src = msg.audio_file_url;
            const label = document.createElement('div');
            label.textContent = 'üéôÔ∏è Original';
            label.style.cssText = 'margin-bottom: 4px; font-weight: 600; font-size: 11px;';
            audioDiv.appendChild(label);
            audioDiv.appendChild(audioEl);
            contentEl.appendChild(audioDiv);
        }
        
        // Transcription text
        const textEl = document.createElement('div');
        textEl.className = 'message-text';
        textEl.textContent = msg.original_text || '(Processing...)';
        contentEl.appendChild(textEl);
        
        // Status badge
        const statusEl = document.createElement('div');
        statusEl.className = 'message-status';
        statusEl.innerHTML = `<span class="status-badge status-${msg.status}">${msg.status}</span>`;
        contentEl.appendChild(statusEl);
        
        messageEl.appendChild(contentEl);
        messagesDiv.appendChild(messageEl);
        messagesDiv.scrollTop = messagesDiv.scrollHeight;
    }
    
    // Update message
    function updateMessage(data) {
        const msgEl = document.getElementById(`msg-${data.message_id}`);
        if (!msgEl) return;
        
        const contentEl = msgEl.querySelector('.message-content');
        const statusEl = contentEl.querySelector('.message-status');
        const textEl = contentEl.querySelector('.message-text');
        
        // Update status
        statusEl.innerHTML = `<span class="status-badge status-${data.status}">${data.status}</span>`;
        
        // Update original text if available - but DON'T overwrite good text with failures
        if (data.original_text) {
            const currentText = textEl.textContent;
            const isFailure = data.original_text.includes('Transcription failed') || data.original_text.startsWith('[');
            const hasGoodText = currentMessageHasGoodText;
            
            // Only update if:
            // 1. It's new good text (not a failure), OR
            // 2. We haven't received good text yet, OR
            // 3. We're updating from a status placeholder like "(Transcribing...)"
            if (!isFailure || !hasGoodText || currentText.includes('(')) {
                if (textEl) {
                    textEl.textContent = data.original_text;
                }
                console.log('Updated message with text:', data.original_text);
                
                // Mark that we have good text if this isn't a failure
                if (!isFailure) {
                    currentMessageHasGoodText = true;
                    console.log('‚úì Message has good transcription, will not overwrite');
                }
            } else {
                console.log('‚è≠Ô∏è Skipping update - keeping good text, ignoring failed transcription');
            }
        }
        
        // Add translated audio if available
        if ((data.status === 'completed' || data.status === 'audio_ready') && data.translated_audio_url) {
            if (!contentEl.querySelector('.message-audio-translated')) {
                const audioDiv = document.createElement('div');
                audioDiv.className = 'message-audio-translated';
                
                const audioEl = document.createElement('audio');
                audioEl.controls = true;
                audioEl.src = data.translated_audio_url;
                
                const label = document.createElement('div');
                label.textContent = 'üîä Translation';
                label.style.cssText = 'margin-bottom: 4px; font-weight: 600; font-size: 11px; margin-top: 6px; padding-top: 6px; border-top: 1px solid rgba(0,0,0,0.1);';
                
                audioDiv.appendChild(label);
                audioDiv.appendChild(audioEl);
                contentEl.appendChild(audioDiv);
                
                // Auto-play if enabled
                if (autoPlayCheckbox.checked) {
                    audioEl.play().catch(e => console.log('Auto-play prevented:', e));
                }
            }
        }
    }
    
    // Setup silence detection with better accuracy
    function setupSilenceDetection(stream) {
        if (!audioContext) {
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
        }
        
        const source = audioContext.createMediaStreamSource(stream);
        analyser = audioContext.createAnalyser();
        analyser.fftSize = 512;
        analyser.smoothingTimeConstant = 0.8;
        source.connect(analyser);
        
        monitorAudioLevel();
    }
    
    // Monitor audio level with Voice Activity Detection
    function monitorAudioLevel() {
        if (!isSessionActive || !analyser) return;
        
        const dataArray = new Uint8Array(analyser.frequencyBinCount);
        analyser.getByteFrequencyData(dataArray);
        
        // Calculate RMS for better level detection
        let sum = 0;
        for (let i = 0; i < dataArray.length; i++) {
            sum += dataArray[i] * dataArray[i];
        }
        const rms = Math.sqrt(sum / dataArray.length);
        
        // Voice Activity Detection logic
        const isSpeech = rms > SPEECH_THRESHOLD;
        
        // Track speech ratio in 2-second window
        totalChecksInWindow++;
        if (isSpeech) {
            speechChecksInWindow++;
        }
        const speechRatio = speechChecksInWindow / totalChecksInWindow;
        
        console.log(`Audio Level: ${rms.toFixed(0)}, Speech: ${isSpeech}, Chunks: ${recordingChunks.length}, SpeechRatio: ${speechRatio.toFixed(2)}`);
        
        if (isSpeech) {
            // User is speaking
            lastSpeechTime = Date.now();
            consecutiveSilenceChecks = 0;
            speechDetectedSinceLastSend = true; // Mark that we have speech
            
            // Start continuous sending timer when speech begins
            if (!continuousSendInterval) {
                console.log('Speech detected - starting continuous send every 2s');
                continuousSendInterval = setInterval(() => {
                    // Only send if we have sufficient speech in this window (>40% speech)
                    const hasSufficientSpeech = speechChecksInWindow / Math.max(1, totalChecksInWindow) >= MIN_SPEECH_RATIO;
                    if (isSessionActive && recordingChunks.length > 0 && hasSufficientSpeech) {
                        console.log(`‚è±Ô∏è Continuous send triggered (${(speechChecksInWindow / Math.max(1, totalChecksInWindow) * 100).toFixed(0)}% speech)`);
                        autoSendAudio(true); // true = continue listening after send
                        // Reset counters for next window
                        speechChecksInWindow = 0;
                        totalChecksInWindow = 0;
                    } else if (!hasSufficientSpeech) {
                        console.log(`‚è≠Ô∏è Skipping send - insufficient speech (${(speechChecksInWindow / Math.max(1, totalChecksInWindow) * 100).toFixed(0)}%)`);
                        recordingChunks = []; // Clear silence chunks
                        speechChecksInWindow = 0;
                        totalChecksInWindow = 0;
                    }
                }, CONTINUOUS_SEND_INTERVAL);
            }
            
            if (silenceDetectionTimeout) {
                clearTimeout(silenceDetectionTimeout);
                silenceDetectionTimeout = null;
                stopSilenceTimer();
            }
        } else {
            // Possible silence - increment counter
            consecutiveSilenceChecks++;
            
            // After silence period, send remaining audio and stop continuous send
            if (consecutiveSilenceChecks >= SILENCE_CHECKS_NEEDED) {
                if (recordingChunks.length > 0) {
                    console.log('Silence reached - sending final chunks');
                    autoSendAudio(false); // false = end of this message
                }
                
                if (continuousSendInterval) {
                    clearInterval(continuousSendInterval);
                    continuousSendInterval = null;
                    console.log('Stopped continuous send');
                }
                currentMessageTempId = null; // Reset for next message
                currentMessageHasGoodText = false; // Reset flag for next message
                speechChecksInWindow = 0; // Reset window counters
                totalChecksInWindow = 0;
                consecutiveSilenceChecks = 0;
            } else if (consecutiveSilenceChecks === 1) {
                // Just started silence
                startSilenceTimer();
            }
        }
        
        // Continue monitoring
        setTimeout(monitorAudioLevel, CHECK_INTERVAL);
    }
    
    function startSilenceTimer() {
        stopSilenceTimer();
        let silenceSeconds = 0;
        silenceTimerInterval = setInterval(() => {
            silenceSeconds++;
            const remaining = Math.max(0, 5 - silenceSeconds);
            silenceTimer.textContent = remaining > 0 ? `${remaining}s` : 'Sending...';
        }, 1000);
        silenceTimer.style.display = 'block';
    }
    
    function stopSilenceTimer() {
        if (silenceTimerInterval) {
            clearInterval(silenceTimerInterval);
            silenceTimerInterval = null;
        }
        silenceTimer.style.display = 'none';
        silenceTimer.textContent = '--';
        consecutiveSilenceChecks = 0;
    }
    
    // Start continuous listening session
    startBtn.addEventListener('click', async () => {
        if (isSessionActive) return;
        
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            mediaRecorder = new MediaRecorder(stream);
            recordingChunks = [];
            sessionStartTime = Date.now();
            isSessionActive = true;
            consecutiveSilenceChecks = 0;
            lastSpeechTime = Date.now();
            speechDetectedSinceLastSend = false;
            currentMessageTempId = null;
            currentMessageHasGoodText = false;
            speechChecksInWindow = 0;
            totalChecksInWindow = 0;
            
            mediaRecorder.ondataavailable = (e) => {
                if (e.data.size > 0) {
                    recordingChunks.push(e.data);
                    console.log('Audio chunk received, total chunks:', recordingChunks.length);
                }
            };
            
            // Start with 500ms timeslice to get periodic data
            mediaRecorder.start(500);
            console.log('MediaRecorder started with 500ms timeslice');
            
            // Setup UI
            startBtn.style.display = 'none';
            stopBtn.style.display = 'block';
            textInput.style.display = 'block';
            sendTextBtn.style.display = 'block';
            listeningIndicator.style.display = 'flex';
            sessionTimer.style.display = 'block';
            
            // Clear empty state
            const emptyState = messagesDiv.querySelector('[style*="No messages"]');
            if (emptyState) emptyState.remove();
            
            // Start timers
            startSessionTimer();
            setupSilenceDetection(stream);
            
            showError('üé§ Session started - Speak naturally!', 'success');
        } catch (err) {
            console.error('Recording error:', err);
            showError('Unable to access microphone. Please check permissions.');
        }
    });
    
    // Auto-send when silence is detected
    function autoSendAudio(isContinuous = false) {
        if (!isSessionActive || recordingChunks.length === 0) {
            console.log('No audio chunks to send, skipping auto-send');
            silenceDetectionTimeout = null;
            stopSilenceTimer();
            return;
        }
        
        // Skip continuous sends if no speech was detected in this batch
        if (isContinuous && !speechDetectedSinceLastSend) {
            console.log('‚ö†Ô∏è No speech detected in this chunk, skipping send');
            recordingChunks = []; // Clear silence/noise chunks
            return;
        }
        
        console.log(`${isContinuous ? '‚è±Ô∏è Continuous' : '‚è∏Ô∏è Final'} send - ${recordingChunks.length} chunks`);
        const blob = new Blob(recordingChunks, { type: 'audio/wav' });
        recordingChunks = []; // Clear for next batch
        consecutiveSilenceChecks = 0; // Reset for next pause detection
        
        // Handle message ID tracking
        let tempId = null;
        if (isContinuous) {
            // Continuous send - create message on first send
            if (!currentMessageTempId) {
                currentMessageTempId = 'msg-' + Date.now();
                const tempMsg = {
                    id: currentMessageTempId,
                    role: 'user',
                    original_text: '(Transcribing...)',
                    status: 'transcribing'
                };
                displayMessage(tempMsg);
            }
            tempId = currentMessageTempId;
        } else {
            // Final send - create new message (or use existing if already created by continuous)
            if (!currentMessageTempId) {
                tempId = 'msg-' + Date.now();
                const tempMsg = {
                    id: tempId,
                    role: 'user',
                    original_text: '(Sending audio...)',
                    status: 'pending'
                };
                displayMessage(tempMsg);
            } else {
                tempId = currentMessageTempId;
            }
        }
        
        const reader = new FileReader();
        reader.onload = () => {
            try {
                const base64 = reader.result.split(',')[1];
                const message = {
                    type: 'audio_message',
                    audio: base64,
                    language: sourceLangSelect.value,
                    temp_id: tempId,
                    is_continuous: isContinuous // Server can group continuous chunks
                };
                socket.send(JSON.stringify(message));
                console.log(`‚úÖ Audio sent - temp_id: ${tempId}`);
                
                // Update message status for continuous send
                if (isContinuous && tempId) {
                    const msgEl = document.getElementById(tempId);
                    if (msgEl) {
                        const statusEl = msgEl.querySelector('.message-status');
                        if (statusEl) {
                            statusEl.innerHTML = `<span class="status-badge status-transcribing">Transcribing...</span>`;
                        }
                    }
                }
            } catch (e) {
                console.error('Error sending audio:', e);
                showError('Error sending audio message');
            }
        };
        reader.readAsDataURL(blob);
        
        // For final send only
        if (!isContinuous) {
            silenceDetectionTimeout = null;
            stopSilenceTimer();
        }
    }
    
    // Stop entire session
    stopBtn.addEventListener('click', () => {
        if (!isSessionActive) return;
        
        isSessionActive = false;
        
        // Stop continuous sending
        if (continuousSendInterval) {
            clearInterval(continuousSendInterval);
            continuousSendInterval = null;
        }
        
        // Send any remaining audio
        if (recordingChunks.length > 0) {
            autoSendAudio(false); // Final send
        }
        
        if (mediaRecorder && mediaRecorder.state === 'recording') {
            mediaRecorder.stop();
            mediaRecorder.stream.getTracks().forEach(track => track.stop());
        }
        
        // Cleanup
        if (silenceDetectionTimeout) {
            clearTimeout(silenceDetectionTimeout);
            silenceDetectionTimeout = null;
        }
        stopSilenceTimer();
        stopSessionTimer();
        
        // Reset UI
        startBtn.style.display = 'block';
        stopBtn.style.display = 'none';
        textInput.style.display = 'none';
        sendTextBtn.style.display = 'none';
        listeningIndicator.style.display = 'none';
        sessionTimer.style.display = 'none';
        
        showError('‚úÖ Session ended', 'success');
    });
    
    // Session timer
    function startSessionTimer() {
        let seconds = 0;
        sessionTimerInterval = setInterval(() => {
            seconds++;
            const mins = Math.floor(seconds / 60);
            const secs = seconds % 60;
            sessionTimer.textContent = `${mins}:${secs.toString().padStart(2, '0')}`;
        }, 1000);
    }
    
    function stopSessionTimer() {
        if (sessionTimerInterval) {
            clearInterval(sessionTimerInterval);
            sessionTimerInterval = null;
        }
        sessionTimer.style.display = 'none';
        sessionTimer.textContent = '0:00';
    }
    
    // Send text message
    sendTextBtn.addEventListener('click', () => {
        const text = textInput.value.trim();
        if (text) {
            const message = {
                type: 'message',
                text: text,
                language: sourceLangSelect.value
            };
            socket.send(JSON.stringify(message));
            textInput.value = '';
        }
    });
    
    textInput.addEventListener('keypress', (e) => {
        if (e.key === 'Enter' && !e.shiftKey) {
            e.preventDefault();
            sendTextBtn.click();
        }
    });
    
    // Settings changes
    [sourceLangSelect, targetLangSelect, autoPlayCheckbox].forEach(el => {
        el.addEventListener('change', () => {
            socket.send(JSON.stringify({
                type: 'settings_update',
                source_language: sourceLangSelect.value,
                target_language: targetLangSelect.value,
                auto_play_translation: autoPlayCheckbox.checked
            }));
        });
    });

    // Show error/notification
    function showError(message, type = 'error') {
        const errorEl = document.createElement('div');
        const bgColor = type === 'success' ? '#d1f0e5' : '#f8d7da';
        const textColor = type === 'success' ? '#0f5132' : '#842029';
        errorEl.style.cssText = `padding: 12px 14px; margin: 10px 0; background: ${bgColor}; color: ${textColor}; border-radius: 6px; font-size: 13px; font-weight: 500;`;
        errorEl.textContent = message;
        messagesDiv.appendChild(errorEl);
        setTimeout(() => errorEl.remove(), type === 'success' ? 3000 : 5000);
    }
    
    // Load existing messages
    function loadMessages() {
        fetch(`/api/chats/${chatId}/messages/`)
            .then(r => r.json())
            .then(data => {
                if (data.length > 0) {
                    data.forEach(msg => displayMessage(msg));
                }
            })
            .catch(e => console.error('Error loading messages:', e));
    }
    
    loadMessages();
</script>
{% endblock %}
